{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Questions"
      ],
      "metadata": {
        "id": "J1ass3Q-oI-a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q1) What is the difference between Character n-gram and Word n-gram? Which one tends to suffer more from the OOV issue?"
      ],
      "metadata": {
        "id": "oMGT15_JoKvC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is the difference between Character n-gram and Word n-gram?\n",
        "\n",
        "Character n-grams\n",
        "Character n-grams are found in text documents by representing the document as a sequence of characters.\n",
        "Character n-grams have proven to be of high quality for authorship attribution.\n",
        "Character n-grams are including whitespaces and punctuation.\n",
        "example, a character 4-gram model results in the following tokens: [It], [It_i], [t_is], [is], [is_a], [s_a_], [_a_s].\n",
        "Word n-grams\n",
        "Word n-grams are found in text documents by representing the document as a sequence of words.\n",
        "example, a character 1-gram model results in the following tokens: [hello], [like], [eat].\n",
        "Which one tends to suffer more from the OOV issue?\n",
        "\n",
        "The word is OOV. An Out-Of-Vocabulary (OOV) Word is a Linguistic Unit or a token that does not appear in training vocabulary or document."
      ],
      "metadata": {
        "id": "OmznulD-oN6J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q2) What is the difference between stop word removal and stemming? Are these techniques language-dependent?"
      ],
      "metadata": {
        "id": "NFQfRT2Kofgh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is the difference between stop word removal and stemming?\n",
        "Stop words:\n",
        "* Stop words are a set of commonly used words in a language. Examples of stop words in English are “a”, “the”, “is”, “are” and etc.\n",
        "* Stop words are commonly used in Text Mining and Natural Language Processing (NLP) to eliminate words that are so commonly used that they carry very little useful information.\n",
        "Stemming:\n",
        "\n",
        "Stemming algorithms work by cutting off the end or the beginning of the word, taking into account a list of common prefixes and suffixes that can be found in an inflected word. Examples of stemming in English are \"studies\" when we use the stemming it will be \"studi\".\n",
        "Are these techniques language-dependent?\n",
        "\n",
        "yes, the stop words and the stemming are language-dependent."
      ],
      "metadata": {
        "id": "MGzZ4Olbohyh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q3) Is tokenization techniques language dependent? Why?"
      ],
      "metadata": {
        "id": "OV-AKAqaoj_K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "yes, tokenization is heavily dependent on language. Each language can have various linguistic rules and exceptions. Languages such as English identify token boundaries via whitespace and punctuation, but other languages such as Chinese require a more complex segmenter to extract tokens from a stream of text that does not contain any whitespaces."
      ],
      "metadata": {
        "id": "_5sixDlaomKR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q4) What is the difference between count vectorizer and tf-idf vectorizer? Would it be feasible to use all possible n-grams? If not, how should you select them?"
      ],
      "metadata": {
        "id": "ZLD55hTqooIq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is the difference between count vectorizer and tf-idf vectorizer?\n",
        "* The time it takes to create the count. Vectorizer is much lesser as compared to your hashing function or the tf-idf representation.\n",
        "* CountVectorizer: Counts the frequency of all words in our corpus, sorts them and grabs the most recurring features (using max_features hyperparameter). But these results are mostly biased and our model might loose out on some of the important less frequent features. These are all boolean values. Ex. SEO People used to take advantage of this.\n",
        "* TFIDFVectorizer: TFIDF is a statistical measure said to have fixed the issues with CountVectorizer in some way. It consists of 2 parts, TF (Term Frequency) multiplied with IDF (Inverse Document Frequency). The main intuition being some words that appear frequently in 1 document and less frequently in other documents could be considered as providing extra insight for that 1 document and could help our model learn from this additional piece of information. In short, common words are penalized. These are relative frequencies identified as floating point numbers.      \n",
        "Would it be feasible to use all possible n-grams? If not, how should you select them?\n",
        "No, This will make it very difficult to assign likelihoods that capture the target of our analysis.\n",
        "it will depand on the model and i will try different n to decide the best n. because If we consider a chunk size of n=2, our results include “The reporters,” “the President,” “the United,” and “the room.” While not perfect, this model successfully identifies three of the relevant entities as candidates in a lightweight fashion.\n",
        "On the other hand, a model based on the small n-gram window of 2 would fail to capture some of the nuance of the original text. For instance, if our sentence is from a text that references multiple heads of state, “the President” could be somewhat ambiguous. In order to capture the entirety of the phrase “the President of the United States,"
      ],
      "metadata": {
        "id": "BXufTSKoorAR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Problem Formulation\n",
        "## Define the problem\n",
        "Because of the rise of social networks and their involvement in other spheres such as politics, false information on the Internet has produced a slew of social issues.\n",
        "We are going to predict if a specific reddit post is fake news or not, by looking at its title.\n",
        "What is the input?\n",
        "## The input is the text feature. it contains various forms of words.\n",
        "\n",
        "## What is the output?\n",
        "If a specific reddit post is fake news or not. In the dataset, the label column is output.\n",
        "\n",
        "## What data mining function is required?\n",
        "In this case, it will be binary Classification that separates data points into different classes (fake or not / 0 or 1) which If a specific reddit post is fake news or not.\n",
        "\n",
        "## What could be the challenges?\n",
        "The data contains various forms of words.\n",
        "The datasets have outliers values.\n",
        "predict a specific reddit post is fake news or not, by looking at its title.\n",
        "## What is the impact?\n",
        "When I create a new system and give it a Feature, it can decide whether If a specific reddit post is fake news or not.\n",
        "\n",
        "# What is an ideal solution?\n",
        "According to my subsequent attempts, Bayesian Search and Random Forest Classifier with Cross Validation. is the best approach because it provides me the highest kaggle score.\n",
        "\n"
      ],
      "metadata": {
        "id": "3bUuSqHSouby"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implementation\n",
        "## Steps\n",
        "## What preprocessing steps are used?\n",
        "Remove outliers.\n",
        "Cleaning the text.\n",
        "Compute the frequency of the words.\n",
        "## What is the experimental protocol used and how was it carried out?\n",
        "Read the data using the function \"read_csv\"\n",
        "Cleaning the text by I'll remove any html tags, digits, single letter chars, stopwords, punctuation, the noise data, convert all whitespaces to single wspace and make stemming.\n",
        "I will split the data to use Holdout method is split the training dataset to training data and validation data using \"train_test_split\".\n",
        "I use Cross validation for training the model well.\n",
        "Determine the optimal values for a given model by using GridSearch, RandomSearch and BayesianSearch.\n",
        "I use Xgboost, Random Forest and Logistic Regression to fit the model.\n",
        "## Important Libraries\n",
        "I will install a package and import several libraries."
      ],
      "metadata": {
        "id": "x1OOFHIEpKt6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "AcL56V1OpFjD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install scikit-optimize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0mTVR0tQhic",
        "outputId": "bc5f9356-79a2-46bb-b502-24f0469c9871"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scikit-optimize\n",
            "  Downloading scikit_optimize-0.9.0-py2.py3-none-any.whl (100 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.3/100.3 KB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.9/dist-packages (from scikit-optimize) (1.1.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.9/dist-packages (from scikit-optimize) (1.2.2)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.9/dist-packages (from scikit-optimize) (1.10.1)\n",
            "Collecting pyaml>=16.9\n",
            "  Downloading pyaml-21.10.1-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.9/dist-packages (from scikit-optimize) (1.22.4)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.9/dist-packages (from pyaml>=16.9->scikit-optimize) (6.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.20.0->scikit-optimize) (3.1.0)\n",
            "Installing collected packages: pyaml, scikit-optimize\n",
            "Successfully installed pyaml-21.10.1 scikit-optimize-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CZn_8nj98Keb"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import pickle\n",
        "import sklearn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "# import holoviews as hv\n",
        "import nltk \n",
        "from bokeh.io import output_notebook\n",
        "output_notebook()\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "# some seeting for pandas and hvplot\n",
        "\n",
        "pd.options.display.max_columns = 100\n",
        "pd.options.display.max_rows = 300\n",
        "pd.options.display.max_colwidth = 100\n",
        "np.set_printoptions(threshold=2000)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "from xgboost import XGBClassifier\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from bokeh.models import NumeralTickFormatter\n",
        "\n",
        "\n",
        "# SelectKBest use for Select features according to the k highest scores. mutual_info_classif utilize the mutual information.\n",
        "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
        "\n",
        "\n",
        "# Provides train/test indices to split data into train/test sets\n",
        "from sklearn.model_selection import PredefinedSplit\n",
        "\n",
        "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
        "\n",
        "# import warnings to prevent show warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "TpmF-BoKKoDd"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Read Data"
      ],
      "metadata": {
        "id": "-71dUqJOpZEa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# reading the training dataset \n",
        "df_train = pd.read_csv('xy_train.csv', index_col='id') \n",
        "# df_train = pd.read_csv('xy_train.csv', index_col='id') \n",
        "# reading the testing dataset \n",
        "df_test = pd.read_csv('x_test.csv', index_col='id') \n",
        "# df_test = pd.read_csv('x_test.csv', index_col='id')"
      ],
      "metadata": {
        "id": "hY6p6foAKy97"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "HUuDbu6pK4Or",
        "outputId": "757955d0-fc49-48a4-994c-878877be45de"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                                       text  \\\n",
              "id                                                                                                            \n",
              "265723  A group of friends began to volunteer at a homeless shelter after their neighbors protested. \"Se...   \n",
              "284269  British Prime Minister @Theresa_May on Nerve Attack on Former Russian Spy: \"The government has c...   \n",
              "207715  In 1961, Goodyear released a kit that allows PS2s to be brought to heel. https://m.youtube.com/w...   \n",
              "551106  Happy Birthday, Bob Barker! The Price Is Right Host on How He'd Like to Be Remembered | \"As the ...   \n",
              "8584    Obama to Nation: 聙\"Innocent Cops and Unarmed Young Black Men Should Not be Dying Before Magic Jo...   \n",
              "...                                                                                                     ...   \n",
              "70046                 Finish Sniper Simo H盲yh盲 during the invasion of Finland by the USSR (1939, colorized)   \n",
              "189377                Nigerian Prince Scam took $110K from Kansas man; 10 years later, he's getting it back   \n",
              "93486                 Is It Safe To Smoke Marijuana During Pregnancy? You鈥檇 Be Surprised Of The Answer | no   \n",
              "140950                Julius Caesar upon realizing that everyone in the room has a knife except him (44 bc)   \n",
              "34509                 Jeff Bridges Releasing 鈥楽leeping Tapes,鈥?a New Album Designed to Help You Fall Asleep   \n",
              "\n",
              "        label  \n",
              "id             \n",
              "265723      0  \n",
              "284269      0  \n",
              "207715      0  \n",
              "551106      0  \n",
              "8584        0  \n",
              "...       ...  \n",
              "70046       0  \n",
              "189377      1  \n",
              "93486       0  \n",
              "140950      0  \n",
              "34509       1  \n",
              "\n",
              "[60000 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f321b751-7aff-4ae0-b8b3-18cfb160af4c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>265723</th>\n",
              "      <td>A group of friends began to volunteer at a homeless shelter after their neighbors protested. \"Se...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284269</th>\n",
              "      <td>British Prime Minister @Theresa_May on Nerve Attack on Former Russian Spy: \"The government has c...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>207715</th>\n",
              "      <td>In 1961, Goodyear released a kit that allows PS2s to be brought to heel. https://m.youtube.com/w...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>551106</th>\n",
              "      <td>Happy Birthday, Bob Barker! The Price Is Right Host on How He'd Like to Be Remembered | \"As the ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8584</th>\n",
              "      <td>Obama to Nation: 聙\"Innocent Cops and Unarmed Young Black Men Should Not be Dying Before Magic Jo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70046</th>\n",
              "      <td>Finish Sniper Simo H盲yh盲 during the invasion of Finland by the USSR (1939, colorized)</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>189377</th>\n",
              "      <td>Nigerian Prince Scam took $110K from Kansas man; 10 years later, he's getting it back</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93486</th>\n",
              "      <td>Is It Safe To Smoke Marijuana During Pregnancy? You鈥檇 Be Surprised Of The Answer | no</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140950</th>\n",
              "      <td>Julius Caesar upon realizing that everyone in the room has a knife except him (44 bc)</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34509</th>\n",
              "      <td>Jeff Bridges Releasing 鈥楽leeping Tapes,鈥?a New Album Designed to Help You Fall Asleep</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>60000 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f321b751-7aff-4ae0-b8b3-18cfb160af4c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f321b751-7aff-4ae0-b8b3-18cfb160af4c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f321b751-7aff-4ae0-b8b3-18cfb160af4c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# show the testing data\n",
        "df_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "4KxoA-6EK8or",
        "outputId": "2a66f82f-e619-41ea-9de4-902a51ce78ba"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                  text\n",
              "id                                                                                    \n",
              "0                                                                           stargazer \n",
              "1                                                                                 yeah\n",
              "2                           PD: Phoenix car thief gets instructions from YouTube video\n",
              "3                       As Trump Accuses Iran, He Has One Problem: His Own Credibility\n",
              "4                                                         \"Believers\" - Hezbollah 2011\n",
              "...                                                                                ...\n",
              "59146                                                Bicycle taxi drivers of New Delhi\n",
              "59147                             Trump blows up GOP's formula for winning House races\n",
              "59148  Napoleon returns from his exile on the island of Elba. (March 1815), Colourised\n",
              "59149                                 Deep down he always wanted to be a ballet dancer\n",
              "59150                        Toddler miraculously survives 6-story fall landing on car\n",
              "\n",
              "[59151 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-40afab8f-00a5-441d-8be3-d90d948fca30\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>stargazer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>yeah</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>PD: Phoenix car thief gets instructions from YouTube video</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>As Trump Accuses Iran, He Has One Problem: His Own Credibility</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\"Believers\" - Hezbollah 2011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59146</th>\n",
              "      <td>Bicycle taxi drivers of New Delhi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59147</th>\n",
              "      <td>Trump blows up GOP's formula for winning House races</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59148</th>\n",
              "      <td>Napoleon returns from his exile on the island of Elba. (March 1815), Colourised</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59149</th>\n",
              "      <td>Deep down he always wanted to be a ballet dancer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59150</th>\n",
              "      <td>Toddler miraculously survives 6-story fall landing on car</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>59151 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-40afab8f-00a5-441d-8be3-d90d948fca30')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-40afab8f-00a5-441d-8be3-d90d948fca30 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-40afab8f-00a5-441d-8be3-d90d948fca30');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check the data have the null values in training data\n",
        "df_train.isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGJhp1_qK_Rz",
        "outputId": "b3c2084c-1c3d-4c59-9cf4-46c5e7ccea44"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "text     0\n",
              "label    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check the data have the null values in testing data\n",
        "df_test.isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iC-49LKPLEPb",
        "outputId": "57c962d8-1ff4-4d9d-9b9d-53442b1b5eb6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "text    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cleaning and preprocessing"
      ],
      "metadata": {
        "id": "Jh66gzjppdli"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# required package for tokenization.\n",
        "nltk.download('punkt') \n",
        "nltk.download('stopwords')\n",
        "\n",
        "# for stemming algorithm\n",
        "stemmer = SnowballStemmer(\"english\")\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "\n",
        "\n",
        "# Make Function to clean text\n",
        "def clean_text(text, for_embedding=False):\n",
        "    \"\"\" steps:\n",
        "        - remove any html tags (< /br> often found)\n",
        "        - Keep only ASCII + European Chars and whitespace, no digits\n",
        "        - remove single letter chars\n",
        "        - convert all whitespaces (tabs etc.) to single wspace\n",
        "        if not for embedding (but e.g. tdf-idf):\n",
        "        - all lowercase\n",
        "        - remove stopwords, punctuation and stemm\n",
        "        - return the clean text\n",
        "    \"\"\"\n",
        "    re_wspace = re.compile(r\"\\s+\", re.IGNORECASE)\n",
        "    re_tags = re.compile(r\"<[^>]+>\")\n",
        "    re_ASII = re.compile(r\"[^A-Za-zÀ-ž ]\", re.IGNORECASE)\n",
        "    re_single_char = re.compile(r\"\\b[A-Za-zÀ-ž]\\b\", re.IGNORECASE)\n",
        "    if for_embedding:\n",
        "        # Keep punctuation\n",
        "        re_ASII = re.compile(r\"[^A-Za-zÀ-ž,.!? ]\", re.IGNORECASE)\n",
        "        re_single_char = re.compile(r\"\\b[A-Za-zÀ-ž,.!?]\\b\", re.IGNORECASE)\n",
        "\n",
        "    text = re.sub(re_tags, \" \", text)\n",
        "    text = re.sub(re_ASII, \" \", text)\n",
        "    text = re.sub(re_single_char, \" \", text)\n",
        "    text = re.sub(re_wspace, \" \", text)\n",
        "\n",
        "    word_tokens = word_tokenize(text)\n",
        "    words_tokens_lower = [word.lower() for word in word_tokens]\n",
        "\n",
        "    if for_embedding:\n",
        "        # no stemming, lowering and punctuation / stop words removal\n",
        "        words_filtered = word_tokens\n",
        "    else:\n",
        "       words_filtered = [\n",
        "            stemmer.stem(word) for word in words_tokens_lower if word not in stop_words\n",
        "        ]\n",
        "\n",
        "    text_clean = \" \".join(words_filtered)\n",
        "    return text_clean"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32PFNwI3LGwD",
        "outputId": "a3cd0440-f4f9-4442-d3ae-ab7a0fef8247"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Clean texts training data \n",
        "df_train[\"text_clean\"] = df_train.loc[df_train[\"text\"].str.len() > 0, \"text\"] # get all text data the length it greater than 0 in training data\n",
        "# call clean_text of method to apply it on text_clean feature in traing data\n",
        "df_train[\"text_clean\"] = df_train[\"text_clean\"].map(\n",
        "    lambda x: clean_text(x, for_embedding=False) if isinstance(x, str) else x  # check if text is instance of string\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lniGnSIsLduM",
        "outputId": "b2c42d64-6326-47c6-b646-ff306c4f66ec"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 20.4 s, sys: 495 µs, total: 20.4 s\n",
            "Wall time: 21.5 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# show the training data\n",
        "df_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 533
        },
        "id": "Jj9zff_pLgC8",
        "outputId": "cc99da30-42fb-4e06-f1ca-fe57af00d9aa"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                                       text  \\\n",
              "id                                                                                                            \n",
              "265723  A group of friends began to volunteer at a homeless shelter after their neighbors protested. \"Se...   \n",
              "284269  British Prime Minister @Theresa_May on Nerve Attack on Former Russian Spy: \"The government has c...   \n",
              "207715  In 1961, Goodyear released a kit that allows PS2s to be brought to heel. https://m.youtube.com/w...   \n",
              "551106  Happy Birthday, Bob Barker! The Price Is Right Host on How He'd Like to Be Remembered | \"As the ...   \n",
              "8584    Obama to Nation: 聙\"Innocent Cops and Unarmed Young Black Men Should Not be Dying Before Magic Jo...   \n",
              "...                                                                                                     ...   \n",
              "70046                 Finish Sniper Simo H盲yh盲 during the invasion of Finland by the USSR (1939, colorized)   \n",
              "189377                Nigerian Prince Scam took $110K from Kansas man; 10 years later, he's getting it back   \n",
              "93486                 Is It Safe To Smoke Marijuana During Pregnancy? You鈥檇 Be Surprised Of The Answer | no   \n",
              "140950                Julius Caesar upon realizing that everyone in the room has a knife except him (44 bc)   \n",
              "34509                 Jeff Bridges Releasing 鈥楽leeping Tapes,鈥?a New Album Designed to Help You Fall Asleep   \n",
              "\n",
              "        label  \\\n",
              "id              \n",
              "265723      0   \n",
              "284269      0   \n",
              "207715      0   \n",
              "551106      0   \n",
              "8584        0   \n",
              "...       ...   \n",
              "70046       0   \n",
              "189377      1   \n",
              "93486       0   \n",
              "140950      0   \n",
              "34509       1   \n",
              "\n",
              "                                                                                                 text_clean  \n",
              "id                                                                                                           \n",
              "265723  group friend began volunt homeless shelter neighbor protest see anoth person also need natur lik...  \n",
              "284269  british prime minist theresa may nerv attack former russian spi govern conclud high like russia ...  \n",
              "207715  goodyear releas kit allow ps brought heel https youtub com watch alxulk cg zwillc fish midatlant...  \n",
              "551106  happi birthday bob barker price right host like rememb man said ave pet spay neuter fuckincorpor...  \n",
              "8584    obama nation innoc cop unarm young black men die magic johnson jimbobshawobodob olymp athlet sho...  \n",
              "...                                                                                                     ...  \n",
              "70046                                                        finish sniper simo yh invas finland ussr color  \n",
              "189377                                               nigerian princ scam took kansa man year later get back  \n",
              "93486                                                          safe smoke marijuana pregnanc surpris answer  \n",
              "140950                                               julius caesar upon realiz everyon room knife except bc  \n",
              "34509                                         jeff bridg releas leep tape new album design help fall asleep  \n",
              "\n",
              "[60000 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5b90773d-c322-4cf3-a22c-b083e28bc93a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>text_clean</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>265723</th>\n",
              "      <td>A group of friends began to volunteer at a homeless shelter after their neighbors protested. \"Se...</td>\n",
              "      <td>0</td>\n",
              "      <td>group friend began volunt homeless shelter neighbor protest see anoth person also need natur lik...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284269</th>\n",
              "      <td>British Prime Minister @Theresa_May on Nerve Attack on Former Russian Spy: \"The government has c...</td>\n",
              "      <td>0</td>\n",
              "      <td>british prime minist theresa may nerv attack former russian spi govern conclud high like russia ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>207715</th>\n",
              "      <td>In 1961, Goodyear released a kit that allows PS2s to be brought to heel. https://m.youtube.com/w...</td>\n",
              "      <td>0</td>\n",
              "      <td>goodyear releas kit allow ps brought heel https youtub com watch alxulk cg zwillc fish midatlant...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>551106</th>\n",
              "      <td>Happy Birthday, Bob Barker! The Price Is Right Host on How He'd Like to Be Remembered | \"As the ...</td>\n",
              "      <td>0</td>\n",
              "      <td>happi birthday bob barker price right host like rememb man said ave pet spay neuter fuckincorpor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8584</th>\n",
              "      <td>Obama to Nation: 聙\"Innocent Cops and Unarmed Young Black Men Should Not be Dying Before Magic Jo...</td>\n",
              "      <td>0</td>\n",
              "      <td>obama nation innoc cop unarm young black men die magic johnson jimbobshawobodob olymp athlet sho...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70046</th>\n",
              "      <td>Finish Sniper Simo H盲yh盲 during the invasion of Finland by the USSR (1939, colorized)</td>\n",
              "      <td>0</td>\n",
              "      <td>finish sniper simo yh invas finland ussr color</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>189377</th>\n",
              "      <td>Nigerian Prince Scam took $110K from Kansas man; 10 years later, he's getting it back</td>\n",
              "      <td>1</td>\n",
              "      <td>nigerian princ scam took kansa man year later get back</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93486</th>\n",
              "      <td>Is It Safe To Smoke Marijuana During Pregnancy? You鈥檇 Be Surprised Of The Answer | no</td>\n",
              "      <td>0</td>\n",
              "      <td>safe smoke marijuana pregnanc surpris answer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140950</th>\n",
              "      <td>Julius Caesar upon realizing that everyone in the room has a knife except him (44 bc)</td>\n",
              "      <td>0</td>\n",
              "      <td>julius caesar upon realiz everyon room knife except bc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34509</th>\n",
              "      <td>Jeff Bridges Releasing 鈥楽leeping Tapes,鈥?a New Album Designed to Help You Fall Asleep</td>\n",
              "      <td>1</td>\n",
              "      <td>jeff bridg releas leep tape new album design help fall asleep</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>60000 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5b90773d-c322-4cf3-a22c-b083e28bc93a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5b90773d-c322-4cf3-a22c-b083e28bc93a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5b90773d-c322-4cf3-a22c-b083e28bc93a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Clean texts testing data\n",
        "df_test[\"text_clean\"] = df_test.loc[df_test[\"text\"].str.len() > 0, \"text\"] # get all text data the length it greater than 0 in testing data\n",
        "# call clean_text of method to apply it on text_clean feature in testing data\n",
        "df_test[\"text_clean\"] = df_test[\"text_clean\"].map(\n",
        "    lambda x: clean_text(x, for_embedding=False) if isinstance(x, str) else x  # check if text is instance of string\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DL3bqwH-Ln5k",
        "outputId": "82cce98e-58fb-49f8-bfc5-ea840a8b4ae5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 10.7 s, sys: 16 ms, total: 10.7 s\n",
            "Wall time: 11.2 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# show the testing data\n",
        "df_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "v5EyL6SJLrp6",
        "outputId": "f8dd7355-33cf-4864-ee92-a75386dabf5a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                  text  \\\n",
              "id                                                                                       \n",
              "0                                                                           stargazer    \n",
              "1                                                                                 yeah   \n",
              "2                           PD: Phoenix car thief gets instructions from YouTube video   \n",
              "3                       As Trump Accuses Iran, He Has One Problem: His Own Credibility   \n",
              "4                                                         \"Believers\" - Hezbollah 2011   \n",
              "...                                                                                ...   \n",
              "59146                                                Bicycle taxi drivers of New Delhi   \n",
              "59147                             Trump blows up GOP's formula for winning House races   \n",
              "59148  Napoleon returns from his exile on the island of Elba. (March 1815), Colourised   \n",
              "59149                                 Deep down he always wanted to be a ballet dancer   \n",
              "59150                        Toddler miraculously survives 6-story fall landing on car   \n",
              "\n",
              "                                            text_clean  \n",
              "id                                                      \n",
              "0                                              stargaz  \n",
              "1                                                 yeah  \n",
              "2       pd phoenix car thief get instruct youtub video  \n",
              "3                 trump accus iran one problem credibl  \n",
              "4                                     believ hezbollah  \n",
              "...                                                ...  \n",
              "59146                     bicycl taxi driver new delhi  \n",
              "59147             trump blow gop formula win hous race  \n",
              "59148  napoleon return exil island elba march colouris  \n",
              "59149                    deep alway want ballet dancer  \n",
              "59150       toddler miracul surviv stori fall land car  \n",
              "\n",
              "[59151 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-19a8c0df-9319-4ec7-8471-39452864d490\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>text_clean</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>stargazer</td>\n",
              "      <td>stargaz</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>yeah</td>\n",
              "      <td>yeah</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>PD: Phoenix car thief gets instructions from YouTube video</td>\n",
              "      <td>pd phoenix car thief get instruct youtub video</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>As Trump Accuses Iran, He Has One Problem: His Own Credibility</td>\n",
              "      <td>trump accus iran one problem credibl</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\"Believers\" - Hezbollah 2011</td>\n",
              "      <td>believ hezbollah</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59146</th>\n",
              "      <td>Bicycle taxi drivers of New Delhi</td>\n",
              "      <td>bicycl taxi driver new delhi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59147</th>\n",
              "      <td>Trump blows up GOP's formula for winning House races</td>\n",
              "      <td>trump blow gop formula win hous race</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59148</th>\n",
              "      <td>Napoleon returns from his exile on the island of Elba. (March 1815), Colourised</td>\n",
              "      <td>napoleon return exil island elba march colouris</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59149</th>\n",
              "      <td>Deep down he always wanted to be a ballet dancer</td>\n",
              "      <td>deep alway want ballet dancer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59150</th>\n",
              "      <td>Toddler miraculously survives 6-story fall landing on car</td>\n",
              "      <td>toddler miracul surviv stori fall land car</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>59151 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-19a8c0df-9319-4ec7-8471-39452864d490')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-19a8c0df-9319-4ec7-8471-39452864d490 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-19a8c0df-9319-4ec7-8471-39452864d490');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Distribution of ratings\n",
        "df_train[\"label\"].value_counts(normalize=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WCWoY8UmLrur",
        "outputId": "75719070-ac66-41a3-a7fd-c64788b4806c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0.536200\n",
              "1    0.459933\n",
              "2    0.003867\n",
              "Name: label, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# remove any values of label have 2\n",
        "df_train = df_train[df_train[\"label\"] != 2]"
      ],
      "metadata": {
        "id": "tVvaHgyeLyfs"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# show the training data\n",
        "df_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 533
        },
        "id": "1Z4Ic12gL1i0",
        "outputId": "7fe91429-2e89-4270-ac8f-25c6965bf72c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                                       text  \\\n",
              "id                                                                                                            \n",
              "265723  A group of friends began to volunteer at a homeless shelter after their neighbors protested. \"Se...   \n",
              "284269  British Prime Minister @Theresa_May on Nerve Attack on Former Russian Spy: \"The government has c...   \n",
              "207715  In 1961, Goodyear released a kit that allows PS2s to be brought to heel. https://m.youtube.com/w...   \n",
              "551106  Happy Birthday, Bob Barker! The Price Is Right Host on How He'd Like to Be Remembered | \"As the ...   \n",
              "8584    Obama to Nation: 聙\"Innocent Cops and Unarmed Young Black Men Should Not be Dying Before Magic Jo...   \n",
              "...                                                                                                     ...   \n",
              "70046                 Finish Sniper Simo H盲yh盲 during the invasion of Finland by the USSR (1939, colorized)   \n",
              "189377                Nigerian Prince Scam took $110K from Kansas man; 10 years later, he's getting it back   \n",
              "93486                 Is It Safe To Smoke Marijuana During Pregnancy? You鈥檇 Be Surprised Of The Answer | no   \n",
              "140950                Julius Caesar upon realizing that everyone in the room has a knife except him (44 bc)   \n",
              "34509                 Jeff Bridges Releasing 鈥楽leeping Tapes,鈥?a New Album Designed to Help You Fall Asleep   \n",
              "\n",
              "        label  \\\n",
              "id              \n",
              "265723      0   \n",
              "284269      0   \n",
              "207715      0   \n",
              "551106      0   \n",
              "8584        0   \n",
              "...       ...   \n",
              "70046       0   \n",
              "189377      1   \n",
              "93486       0   \n",
              "140950      0   \n",
              "34509       1   \n",
              "\n",
              "                                                                                                 text_clean  \n",
              "id                                                                                                           \n",
              "265723  group friend began volunt homeless shelter neighbor protest see anoth person also need natur lik...  \n",
              "284269  british prime minist theresa may nerv attack former russian spi govern conclud high like russia ...  \n",
              "207715  goodyear releas kit allow ps brought heel https youtub com watch alxulk cg zwillc fish midatlant...  \n",
              "551106  happi birthday bob barker price right host like rememb man said ave pet spay neuter fuckincorpor...  \n",
              "8584    obama nation innoc cop unarm young black men die magic johnson jimbobshawobodob olymp athlet sho...  \n",
              "...                                                                                                     ...  \n",
              "70046                                                        finish sniper simo yh invas finland ussr color  \n",
              "189377                                               nigerian princ scam took kansa man year later get back  \n",
              "93486                                                          safe smoke marijuana pregnanc surpris answer  \n",
              "140950                                               julius caesar upon realiz everyon room knife except bc  \n",
              "34509                                         jeff bridg releas leep tape new album design help fall asleep  \n",
              "\n",
              "[59768 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b8d9e1cc-6853-420a-8cb7-7aed577c0b9d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>text_clean</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>265723</th>\n",
              "      <td>A group of friends began to volunteer at a homeless shelter after their neighbors protested. \"Se...</td>\n",
              "      <td>0</td>\n",
              "      <td>group friend began volunt homeless shelter neighbor protest see anoth person also need natur lik...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284269</th>\n",
              "      <td>British Prime Minister @Theresa_May on Nerve Attack on Former Russian Spy: \"The government has c...</td>\n",
              "      <td>0</td>\n",
              "      <td>british prime minist theresa may nerv attack former russian spi govern conclud high like russia ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>207715</th>\n",
              "      <td>In 1961, Goodyear released a kit that allows PS2s to be brought to heel. https://m.youtube.com/w...</td>\n",
              "      <td>0</td>\n",
              "      <td>goodyear releas kit allow ps brought heel https youtub com watch alxulk cg zwillc fish midatlant...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>551106</th>\n",
              "      <td>Happy Birthday, Bob Barker! The Price Is Right Host on How He'd Like to Be Remembered | \"As the ...</td>\n",
              "      <td>0</td>\n",
              "      <td>happi birthday bob barker price right host like rememb man said ave pet spay neuter fuckincorpor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8584</th>\n",
              "      <td>Obama to Nation: 聙\"Innocent Cops and Unarmed Young Black Men Should Not be Dying Before Magic Jo...</td>\n",
              "      <td>0</td>\n",
              "      <td>obama nation innoc cop unarm young black men die magic johnson jimbobshawobodob olymp athlet sho...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70046</th>\n",
              "      <td>Finish Sniper Simo H盲yh盲 during the invasion of Finland by the USSR (1939, colorized)</td>\n",
              "      <td>0</td>\n",
              "      <td>finish sniper simo yh invas finland ussr color</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>189377</th>\n",
              "      <td>Nigerian Prince Scam took $110K from Kansas man; 10 years later, he's getting it back</td>\n",
              "      <td>1</td>\n",
              "      <td>nigerian princ scam took kansa man year later get back</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93486</th>\n",
              "      <td>Is It Safe To Smoke Marijuana During Pregnancy? You鈥檇 Be Surprised Of The Answer | no</td>\n",
              "      <td>0</td>\n",
              "      <td>safe smoke marijuana pregnanc surpris answer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140950</th>\n",
              "      <td>Julius Caesar upon realizing that everyone in the room has a knife except him (44 bc)</td>\n",
              "      <td>0</td>\n",
              "      <td>julius caesar upon realiz everyon room knife except bc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34509</th>\n",
              "      <td>Jeff Bridges Releasing 鈥楽leeping Tapes,鈥?a New Album Designed to Help You Fall Asleep</td>\n",
              "      <td>1</td>\n",
              "      <td>jeff bridg releas leep tape new album design help fall asleep</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>59768 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b8d9e1cc-6853-420a-8cb7-7aed577c0b9d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b8d9e1cc-6853-420a-8cb7-7aed577c0b9d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b8d9e1cc-6853-420a-8cb7-7aed577c0b9d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Distribution of ratings\n",
        "df_train[\"label\"].value_counts(normalize=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OSLJXSjL3Oz",
        "outputId": "bbf6b66f-adc1-49b2-ae9f-268a15441e23"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0.538281\n",
              "1    0.461719\n",
              "Name: label, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set the text_clean feature and label to values in training data \n",
        "X = df_train[\"text_clean\"]\n",
        "Y = df_train[\"label\"]"
      ],
      "metadata": {
        "id": "PSP_q-oFL7fc"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Functions"
      ],
      "metadata": {
        "id": "c9h30T6gpkea"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a Function to Pipeline vectorizer and my_classifier\n",
        "# combine the vectorizer with the model as a full tunable pipeline\n",
        "# we gave them a name so we can set their hyperparameters\n",
        "\n",
        "def create_fit_pipeline(my_classifier):\n",
        "  full_pipeline = Pipeline(\n",
        "      steps=[\n",
        "          (\"vectorizer\", TfidfVectorizer(norm=\"l2\")), \n",
        "          ('my_classifier', my_classifier)\n",
        "      ]\n",
        "  )\n",
        "  # The pipeline object can be used like any sk-learn model and training it \n",
        "  full_pipeline = full_pipeline.fit(X, Y)\n",
        "  return full_pipeline"
      ],
      "metadata": {
        "id": "VHQQrrYSMFIE"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make Funiction to prediction the pipeline\n",
        "def predict_pipeline(full_pipeline):\n",
        "  # prediction the df_test\n",
        "  y_pred = full_pipeline.predict(df_test)\n",
        "  # Show unique and count values\n",
        "  return pd.DataFrame(y_pred).value_counts()"
      ],
      "metadata": {
        "id": "Hd1bE5fRMPA8"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a Function for predict the testing data and save it in the csv file\n",
        "def predict_save_csv(search_model, classifier_name):\n",
        "  submission = pd.DataFrame()\n",
        "  submission['id'] = df_test.index\n",
        "  submission['label'] = search_model.predict_proba(df_test.text_clean)[:,1]\n",
        "  file_name = 'Compition_3_' + classifier_name + '.csv'\n",
        "  submission.to_csv(file_name, index=False)"
      ],
      "metadata": {
        "id": "-Z_wRxBeMQ98"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Further split the original training set to a train and a validation set\n",
        "X_train2, X_val, y_train2, y_val = train_test_split(\n",
        "    X, Y, train_size = 0.8, stratify = Y, random_state = 42)\n",
        "\n",
        "# Create a list where train data indices are -1 and validation data indices are 0\n",
        "# X_train2 (new training set), X_train\n",
        "split_index = [-1 if x in X_train2.index else 0 for x in X.index]\n",
        "\n",
        "# Use the list to create PredefinedSplit\n",
        "pds = PredefinedSplit(test_fold = split_index)"
      ],
      "metadata": {
        "id": "f9V0cg-hMcnL"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Grid Search"
      ],
      "metadata": {
        "id": "XQOL4U5vpvHw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make Function to create and fit the Grid Search to pipeline\n",
        "\n",
        "def create_fit_grid_search(full_pipeline, param_grid, cv):\n",
        "  # cv means number of K-fold cross-validation or validation set\n",
        "  # n_jobs means the cucurrent number of jobs (on colab since we only have two cpu cores, we set it to 2)\n",
        "\n",
        "  grid_search = GridSearchCV(\n",
        "      full_pipeline, param_grid, cv=cv, verbose=1, n_jobs=2, \n",
        "      scoring='roc_auc') # create object GridSearchCV\n",
        "\n",
        "  grid_search.fit(X, Y) # train the gridsearch\n",
        "\n",
        "  print('best score {}'.format(grid_search.best_score_)) # print the best score of model\n",
        "  print('best score {}'.format(grid_search.best_params_)) # print the best hyperparameters of model\n",
        "  return grid_search"
      ],
      "metadata": {
        "id": "i_iXIEZBMhg7"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Search"
      ],
      "metadata": {
        "id": "t2GZf1Z7pxA4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make Function to create and fit the Random Search to pipeline\n",
        "\n",
        "def create_fit_random_search(full_pipeline, param_random, cv):\n",
        "  # cv= cv means cv-fold cross-validation or validation set\n",
        "  # n_jobs means the cucurrent number of jobs\n",
        "  # (on colab since we only have two cpu cores, we set it to 2)\n",
        "  random_search = RandomizedSearchCV(\n",
        "      full_pipeline, param_random, cv=cv, verbose=1, n_jobs=2, \n",
        "      # number of random trials\n",
        "      n_iter=5,\n",
        "      scoring='roc_auc')\n",
        "\n",
        "  random_search.fit(X, Y)\n",
        "\n",
        "  print('best score {}'.format(random_search.best_score_)) # print the best score of model\n",
        "  print('best score {}'.format(random_search.best_params_)) # print the best hyperparameters of model\n",
        "  return random_search"
      ],
      "metadata": {
        "id": "eRDR2RpvO7Nk"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bayesian Search"
      ],
      "metadata": {
        "id": "VZ09f3x2pzkn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from skopt import BayesSearchCV\n",
        "# Make Function to create and fit the Bayesian Search to pipeline\n",
        "\n",
        "def create_fit_bayesian_search(full_pipeline, param_bayesian, cv):\n",
        "  # cv= cv means cv-fold cross-validation or validation set\n",
        "  # n_jobs means the cucurrent number of jobs\n",
        "  # (on colab since we only have two cpu cores, we set it to 2)\n",
        "    Bayes_search = BayesSearchCV(\n",
        "      full_pipeline, param_bayesian, cv=cv, verbose=1, n_jobs=2, \n",
        "      # number of Bayes trials\n",
        "      n_iter=5)\n",
        "\n",
        "    Bayes_search.fit(X, Y)\n",
        "\n",
        "    print('best score {}'.format(Bayes_search.best_score_)) # print the best score of model\n",
        "    print('best score {}'.format(Bayes_search.best_params_)) # print the best hyperparameters of model\n",
        "    return Bayes_search"
      ],
      "metadata": {
        "id": "0esap-3kQBkV"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for the create pipeline with my classifier is XGBoost Classifier\n",
        "full_pipeline_XGB = create_fit_pipeline(XGBClassifier(objective='binary:logistic', silent=True, random_state= 42))\n",
        "# prediction the pipeline\n",
        "predict_pipeline(full_pipeline_XGB)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjcRMGMnMldU",
        "outputId": "f7612436-bac0-410c-9856-825676f99487"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15:49:53] WARNING: ../src/learner.cc:767: \n",
            "Parameters: { \"silent\" } are not used.\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    2\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1* XGBoost"
      ],
      "metadata": {
        "id": "JcPgXX2wp36v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameter for XGBoost Classifier\n",
        "# here we specify the search space \n",
        "# `__` denotes an attribute of the preceeding name\n",
        "# (e.g. my_classifier__n_estimators means the `n_estimators` param for `my_classifier`)\n",
        "param_XGB = {\n",
        "    'vectorizer__analyzer': [\"word\"], \n",
        "    'vectorizer__max_df': [0.3, 0.4, 0.5, 0.6, 0.7, 0.8],\n",
        "    # 'vectorizer__ngram_range' : [(1, 2)],\n",
        "    'vectorizer__min_df': [5, 10, 15, 20, 25, 30],\n",
        "    \n",
        "\n",
        "    'my_classifier__learning_rate' : [0.005, 0.001, 0.01, 0.02, 0.03, 0.05, 0.1, 0.2, 0.3],\n",
        "    'my_classifier__n_estimators' : [600,1000, 1100, 1500, 2000, 3000, 4000],\n",
        "    'my_classifier__nthread' : [1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
        "#     'my_classifier__min_child_weight': [1, 5, 10],\n",
        "#     'my_classifier__gamma': [0.4, 0.5, 0.6, 1, 1.5, 2, 2.5, 3, 5],\n",
        "    'my_classifier__subsample': [0.05, 0.2, 0.3, 0.6, 0.8, 0.9],\n",
        "    'my_classifier__colsample_bytree': [0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
        "#     'my_classifier__max_depth': np.arange(3, 20),\n",
        "#     'my_classifier__random_state' : [0, 1, 42, 15]\n",
        "}"
      ],
      "metadata": {
        "id": "HPpoTnjYM2Pc"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# using the create_fit_bayesian_search function and it will return bayesian_search for XGBoost and it will use the (X) and (Y)\n",
        "bayesian_search_XGB = create_fit_bayesian_search(full_pipeline_XGB, param_XGB, 3)\n",
        "print(\"Best: %f using %s\" % (bayesian_search_XGB.best_score_, bayesian_search_XGB.best_params_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5p7FPdDUNwxS",
        "outputId": "3a7b215b-f3bc-41ad-dcea-cd82b1233983"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[16:17:44] WARNING: ../src/learner.cc:767: \n",
            "Parameters: { \"silent\" } are not used.\n",
            "\n",
            "best score 0.7479253119020157\n",
            "best score OrderedDict([('my_classifier__colsample_bytree', 0.9), ('my_classifier__learning_rate', 0.01), ('my_classifier__n_estimators', 4000), ('my_classifier__nthread', 8), ('my_classifier__subsample', 0.6), ('vectorizer__analyzer', 'word'), ('vectorizer__max_df', 0.8), ('vectorizer__min_df', 25)])\n",
            "Best: 0.747925 using OrderedDict([('my_classifier__colsample_bytree', 0.9), ('my_classifier__learning_rate', 0.01), ('my_classifier__n_estimators', 4000), ('my_classifier__nthread', 8), ('my_classifier__subsample', 0.6), ('vectorizer__analyzer', 'word'), ('vectorizer__max_df', 0.8), ('vectorizer__min_df', 25)])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# using the predict_save_csv function and it will predict the testing data and save it in the csv file\n",
        "predict_save_csv(bayesian_search_XGB, 'XGB_Bayesian_Cross')"
      ],
      "metadata": {
        "id": "QR3o0gfQTbpD"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for the create pipeline with my classifier is RandomForestClassifier\n",
        "full_pipeline_Randomforst = create_fit_pipeline(RandomForestClassifier())"
      ],
      "metadata": {
        "id": "xe8IabFITbjl"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameter for RandomForestClassifier\n",
        "# here we specify the search space \n",
        "# `__` denotes an attribute of the preceeding name\n",
        "# (e.g. my_classifier__n_estimators means the `n_estimators` param for `my_classifier`)\n",
        "param_RandomForest = {\n",
        "    'vectorizer__analyzer': [\"word\"], \n",
        "    'vectorizer__max_df': np.arange(0.3, 0.8),\n",
        "    'vectorizer__min_df': range(5, 30, 5),\n",
        "    'vectorizer__ngram_range': [(1, 2)], \n",
        "\n",
        "\n",
        "\n",
        "    'my_classifier__n_estimators': range(500, 1000, 100),\n",
        "    'my_classifier__criterion' :['gini', 'entropy'],\n",
        "#     'my_classifier__max_features' : ['auto', 'sqrt', 'log2'],\n",
        "     # my_classifier__n_estimators points to my_classifier->n_estimators \n",
        "    # 'my_classifier__max_depth': [100, 200, 400, 600, 2000]       \n",
        "}"
      ],
      "metadata": {
        "id": "QoYZAukdTphz"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# using the create_fit_grid_search function and it will return grid_search for RandomForestClassifier and it will use the use the (X) and (Y)\n",
        "grid_search_RandomForest = create_fit_grid_search(full_pipeline_Randomforst, param_RandomForest, pds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "id": "FZW1GWrmTqIc",
        "outputId": "ee373c3f-87fc-4238-89fb-b41ad5916df1"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 1 folds for each of 50 candidates, totalling 50 fits\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-60-9e69738cf2cc>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# using the create_fit_grid_search function and it will return grid_search for RandomForestClassifier and it will use the use the (X) and (Y)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgrid_search_RandomForest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_fit_grid_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_pipeline_Randomforst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_RandomForest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-23-278085ea67d8>\u001b[0m in \u001b[0;36mcreate_fit_grid_search\u001b[0;34m(full_pipeline, param_grid, cv)\u001b[0m\n\u001b[1;32m      9\u001b[0m       scoring='roc_auc') # create object GridSearchCV\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m   \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# train the gridsearch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'best score {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# print the best score of model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    872\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 874\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1386\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1387\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1388\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    819\u001b[0m                     )\n\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    822\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    823\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1059\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1060\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1061\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1062\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1063\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    936\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 938\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    939\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    940\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    439\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# using the predict_save_csv function and it will predict the testing data and save it in the csv file\n",
        "predict_save_csv(grid_search_RandomForest, 'RF_Grid_Validation')"
      ],
      "metadata": {
        "id": "yYLQridGTs67"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# using the create_fit_Random_search function and it will return Random_search for Random Forest and it will use the (X) and (Y)\n",
        "random_search_RF = create_fit_random_search(full_pipeline_Randomforst, param_RandomForest, pds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0jWeA7uT-se",
        "outputId": "570fa516-fe01-465d-8d67-89b741fea3ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 1 folds for each of 5 candidates, totalling 5 fits\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# using the predict_save_csv function and it will predict the testing data and save it in the csv file\n",
        "predict_save_csv(random_search_RF, 'RF_random_Validation')"
      ],
      "metadata": {
        "id": "HASZfpG_UA18"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameter for RandomForestClassifier\n",
        "# here we specify the search space \n",
        "# `__` denotes an attribute of the preceeding name\n",
        "# (e.g. my_classifier__n_estimators means the `n_estimators` param for `my_classifier`)\n",
        "param_RandomForest = {\n",
        "    'vectorizer__analyzer': [\"word\"], \n",
        "    'vectorizer__max_df': [0.3, 0.4, 0.5, 0.6, 0.7, 0.8],\n",
        "    'vectorizer__min_df': [5, 10, 15, 20, 25, 30],\n",
        "    # 'vectorizer__ngram_range': [(1, 2)], \n",
        "\n",
        "\n",
        "\n",
        "    'my_classifier__n_estimators': [500, 600, 700, 800, 900, 1000],\n",
        "    'my_classifier__criterion' :['gini', 'entropy'],\n",
        "    'my_classifier__max_features' : ['auto', 'sqrt', 'log2'],\n",
        "     # my_classifier__n_estimators points to my_classifier->n_estimators \n",
        "    # 'my_classifier__max_depth': [100, 200, 400, 600, 2000]       \n",
        "}"
      ],
      "metadata": {
        "id": "WSv33dQFUH0T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# using the create_fit_Bayesian_search function and it will return Bayesian_search for XGBoost and it will use the (x_train) and (y_train)\n",
        "bayesian_search_RF = create_fit_bayesian_search(full_pipeline_Randomforst, param_RandomForest, 20)"
      ],
      "metadata": {
        "id": "-ORBHHLMU47T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# using the predict_save_csv function and it will predict the testing data and save it in the csv file\n",
        "predict_save_csv(bayesian_search_RF, 'RF_bayesian_Cross')"
      ],
      "metadata": {
        "id": "_UCYCMfPU6vz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for the create pipeline with my classifier is Logistic Regression Classifier\n",
        "full_pipeline_Log = create_fit_pipeline(LogisticRegression(random_state = 42))"
      ],
      "metadata": {
        "id": "ToZE1CM2U8x7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameter for Logistic Regression Classifier\n",
        "# here we specify the search space \n",
        "# `__` denotes an attribute of the preceeding name\n",
        "# (e.g. my_classifier__n_estimators means the `n_estimators` param for `my_classifier`)\n",
        "param_Log = {\n",
        "    'vectorizer__analyzer': [\"word\"], \n",
        "    'vectorizer__max_df': [0.3, 0.4, 0.5, 0.6, 0.7, 0.8],\n",
        "    'vectorizer__min_df': [5, 10, 15, 20, 25, 30, 35, 40, 50],\n",
        "    \n",
        "    'my_classifier__penalty' : ['l1', 'l2', 'elasticnet'],\n",
        "    'my_classifier__C' : [0.001,0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.1, 1],\n",
        "    'my_classifier__solver' : ['newton-cg', 'sag', 'saga', 'lbfgs']\n",
        "}"
      ],
      "metadata": {
        "id": "BdwebAHBU-ob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# using the create_fit_grid_search function and it will return grid_search for Logistic Regression and it will use the (x_train) and (y_train)\n",
        "random_search_Log = create_fit_random_search(full_pipeline_Log, param_Log, 20)"
      ],
      "metadata": {
        "id": "r-yOU-gSVApb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# using the predict_save_csv function and it will predict the testing data and save it in the csv file\n",
        "predict_save_csv(random_search_Log, 'Log_Random_Cross')"
      ],
      "metadata": {
        "id": "TjulRKYgVD47"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameter for Logistic Regression Classifier\n",
        "# here we specify the search space \n",
        "# `__` denotes an attribute of the preceeding name\n",
        "# (e.g. my_classifier__n_estimators means the `n_estimators` param for `my_classifier`)\n",
        "param_Log = {\n",
        "    'vectorizer__analyzer': [\"char\"], \n",
        "    'vectorizer__max_df': [0.3, 0.4, 0.5, 0.6, 0.7, 0.8],\n",
        "    'vectorizer__min_df': [5, 10, 15, 20, 25, 30, 35, 40, 50],\n",
        "    \n",
        "    'my_classifier__penalty' : ['l2', 'none'],\n",
        "    'my_classifier__C' : [0.001,0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.1, 1, 2, 2.5],\n",
        "    'my_classifier__solver' : ['newton-cg', 'sag', 'saga', 'lbfgs']\n",
        "}"
      ],
      "metadata": {
        "id": "f51ZyhEkVEZ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# using the create_fit_grid_search function and it will return grid_search for Logistic Regression and it will use the (x_train) and (y_train)\n",
        "random_search_Log = create_fit_random_search(full_pipeline_Log, param_Log, pds)"
      ],
      "metadata": {
        "id": "S8BFSIW5VNnc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# using the predict_save_csv function and it will predict the testing data and save it in the csv file\n",
        "predict_save_csv(random_search_Log, 'Log_Random_Validation')"
      ],
      "metadata": {
        "id": "qGZqDWJFVPTj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameter for Logistic Regression Classifier\n",
        "# here we specify the search space \n",
        "# `__` denotes an attribute of the preceeding name\n",
        "# (e.g. my_classifier__n_estimators means the `n_estimators` param for `my_classifier`)\n",
        "param_Log = {\n",
        "    'vectorizer__analyzer': [\"word\"], \n",
        "    'vectorizer__max_df': [0.3, 0.4, 0.5, 0.6, 0.7, 0.8],\n",
        "    'vectorizer__min_df': [5, 10, 15, 20, 25, 30, 35, 40, 50],\n",
        "    \n",
        "    'my_classifier__penalty' : ['l2', 'none'],\n",
        "    'my_classifier__C' : [0.001,0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.1, 1],\n",
        "    'my_classifier__solver' : ['newton-cg', 'sag', 'saga', 'lbfgs']\n",
        "}"
      ],
      "metadata": {
        "id": "4fmxdPE2VQib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# using the create_fit_grid_search function and it will return grid_search for Logistic Regression and it will use the (x_train) and (y_train)\n",
        "bayesian_search_Log = create_fit_bayesian_search(full_pipeline_Log, param_Log, 20)"
      ],
      "metadata": {
        "id": "HVID_9oPVSk7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# using the predict_save_csv function and it will predict the testing data and save it in the csv file\n",
        "predict_save_csv(bayesian_search_Log, 'Log_Bayesian_Cross')"
      ],
      "metadata": {
        "id": "2ESYdfalVUJL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameter for Logistic Regression Classifier\n",
        "# here we specify the search space \n",
        "# `__` denotes an attribute of the preceeding name\n",
        "# (e.g. my_classifier__n_estimators means the `n_estimators` param for `my_classifier`)\n",
        "param_Log = {\n",
        "    'vectorizer__analyzer': [\"char\"], \n",
        "    'vectorizer__max_df': [0.3, 0.4, 0.5, 0.6, 0.7, 0.8],\n",
        "    'vectorizer__min_df': [5, 10, 15, 20, 25, 30, 35, 40, 50],\n",
        "    \n",
        "    'my_classifier__penalty' : ['l2', 'none'],\n",
        "    'my_classifier__C' : [0.001,0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.1, 1],\n",
        "    'my_classifier__solver' : ['newton-cg', 'sag', 'saga', 'lbfgs']\n",
        "}"
      ],
      "metadata": {
        "id": "kcBF2puEVXB7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# using the create_fit_grid_search function and it will return grid_search for Logistic Regression and it will use the (x_train) and (y_train)\n",
        "bayesian_search_Log = create_fit_bayesian_search(full_pipeline_Log, param_Log, pds)"
      ],
      "metadata": {
        "id": "z5DU4bH-VXek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# using the predict_save_csv function and it will predict the testing data and save it in the csv file\n",
        "predict_save_csv(bayesian_search_Log, 'Log_Bayesian_Validation')"
      ],
      "metadata": {
        "id": "yxsObzusVZYU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}